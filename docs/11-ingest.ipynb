{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: Data Ingestion\n",
    "author: Sonny Bhatia\n",
    "description: Read Polis data, calculate embeddings, and store in Polars Dataframe\n",
    "image: /images/11-ingest.webp\n",
    "date: 2024-03-01\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Polis datasets are publicly available at [github.com/compdemocracy/openData](https://github.com/compdemocracy/openData). We download these datasets and read the CSV files using [Polars DataFrame library](https://docs.pola.rs/). Once we have the data available in our Python environment, we use [Sentence Transformers](https://www.sbert.net/) to compute embeddings for each comment in the dataset and store that alongside the original data in our DataFrame. Then we save the DataFrame to a parquet file for further analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages and Setup Environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'answerdotai/ModernBERT-base'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import polars as pl\n",
    "\n",
    "from argmap.dataModel import Summary, Comments\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.getenv(\"EMBED_MODEL_ID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Embedding Model\n",
    "\n",
    "Here we consider several embedding models based on [HuggingFace Massive Text Embedding Benchmark (MTEB) Leaderboard](https://huggingface.co/spaces/mteb/leaderboard). The following models are considered:\n",
    "\n",
    "- [intfloat/e5-mistral-7b-instruct](https://huggingface.co/intfloat/e5-mistral-7b-instruct) - 4096 dimensions, requires 14.5 GB RAM\n",
    "- [WhereIsAI/UAE-Large-V1](https://huggingface.co/WhereIsAI/UAE-Large-V1) - 1024 dimensions, requires 1.5 GB RAM\n",
    "- [Salesforce/SFR-Embedding-Mistral](https://huggingface.co/Salesforce/SFR-Embedding-Mistral) - consistently scores top, untested\n",
    "- [OpenAI/text-embedding-3-large](https://openai.com/blog/new-embedding-models-and-api-updates) - hosted by OpenAI, not open source\n",
    "- [OpenAI/text-embedding-ada-002](https://openai.com/blog/new-and-improved-embedding-model) - hosted by OpenAI, not open source\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify GPU Availability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.11.11 | packaged by conda-forge | (main, Dec  5 2024, 14:21:42) [Clang 18.1.8 ]\n",
      "PyTorch: 2.5.1\n",
      "No CUDA support. Using CPU.\n"
     ]
    }
   ],
   "source": [
    "from argmap.helpers import printTorchDeviceVersion\n",
    "\n",
    "printTorchDeviceVersion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name answerdotai/ModernBERT-base. Creating a new one with mean pooling.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-26 17:45:51.968672 Initializing embedding model: answerdotai/ModernBERT-base on cpu...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running on CPU - no CUDA memory to report\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-26 17:45:53.117035 Embedding model initialized.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from argmap.helpers import ensureCUDAMemory, printCUDAMemory, loadEmbeddingModel\n",
    "\n",
    "if os.getenv(\"EMBED_MODEL_ID\") is None:\n",
    "    print(\"EMBED_MODEL_ID environment variable is required.\")\n",
    "    sys.exit(3)\n",
    "\n",
    "model = loadEmbeddingModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate and Store Embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_embeddings(comments, model, show_progress_bar=False):\n",
    "    documents = comments.df.get_column(\"commentText\").to_list()\n",
    "    embeddings = model.encode(documents, show_progress_bar=show_progress_bar)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "american-assembly.bowling-green: Loaded 896 comments from original dataset CSV.\n",
      "Topic: Improving Bowling Green / Warren County\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3f342b359ac42988d758ddb247c091b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "american-assembly.bowling-green: Saved 896 comments with embeddings to Parquet DataFrame.\n",
      "\n",
      "march-on.operation-marchin-orders: Loaded 2162 comments from original dataset CSV.\n",
      "Topic: Operation Marching Orders\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d804cd2dfd2425787445ff54de932c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/68 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "march-on.operation-marchin-orders: Saved 2162 comments with embeddings to Parquet DataFrame.\n",
      "\n",
      "scoop-hivemind.biodiversity: Loaded 316 comments from original dataset CSV.\n",
      "Topic: Protecting and Restoring NZâ€™s Biodiversity\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce9b5263c29140b689c5d8f7044bb153",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scoop-hivemind.biodiversity: Saved 316 comments with embeddings to Parquet DataFrame.\n",
      "\n",
      "scoop-hivemind.freshwater: Loaded 80 comments from original dataset CSV.\n",
      "Topic: HiveMind - Freshwater Quality in NZ\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03969d849f1b40ad85915cecfbcd7dca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scoop-hivemind.freshwater: Saved 80 comments with embeddings to Parquet DataFrame.\n",
      "\n",
      "scoop-hivemind.taxes: Loaded 148 comments from original dataset CSV.\n",
      "Topic: Tax HiveMind Window\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6d4ec0597df4575ac41c4a28d655604",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scoop-hivemind.taxes: Saved 148 comments with embeddings to Parquet DataFrame.\n",
      "\n",
      "scoop-hivemind.ubi: Loaded 71 comments from original dataset CSV.\n",
      "Topic: A Universal Basic Income for Aotearoa NZ?\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85c6ee3f686b4bf4aa3fc5c6b0cb4687",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scoop-hivemind.ubi: Saved 71 comments with embeddings to Parquet DataFrame.\n",
      "\n",
      "scoop-hivemind.affordable-housing: Loaded 165 comments from original dataset CSV.\n",
      "Topic: ScoopNZ Hivemind on affordable housing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09429aa4f8954b3d9cb4d40ef0919d15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scoop-hivemind.affordable-housing: Saved 165 comments with embeddings to Parquet DataFrame.\n",
      "\n",
      "ssis.land-bank-farmland.2rumnecbeh.2021-08-01: Loaded 297 comments from original dataset CSV.\n",
      "Topic: JOIN THE DISCUSSION BELOW: Land use and conservation in the San Juan Islands\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "395bb69dcfbc4fc990df5d483d23a919",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssis.land-bank-farmland.2rumnecbeh.2021-08-01: Saved 297 comments with embeddings to Parquet DataFrame.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from argmap.dataModel import Summary, Comments\n",
    "\n",
    "DATASETS = [\n",
    "    \"american-assembly.bowling-green\",\n",
    "    \"march-on.operation-marchin-orders\",\n",
    "    \"scoop-hivemind.biodiversity\",\n",
    "    \"scoop-hivemind.freshwater\",\n",
    "    \"scoop-hivemind.taxes\",\n",
    "    \"scoop-hivemind.ubi\",\n",
    "    \"scoop-hivemind.affordable-housing\",\n",
    "    \"ssis.land-bank-farmland.2rumnecbeh.2021-08-01\",\n",
    "]\n",
    "\n",
    "for dataset in DATASETS:\n",
    "\n",
    "    summary = Summary(dataset)\n",
    "    comments = Comments(dataset)\n",
    "\n",
    "    if os.path.exists(comments.filename):\n",
    "        comments.load_from_parquet()\n",
    "        print(f\"{dataset}: Loaded {comments.df.height} comments from Parquet DataFrame.\")\n",
    "    else:\n",
    "        comments.load_from_csv()\n",
    "        print(f\"{dataset}: Loaded {comments.df.height} comments from original dataset CSV.\")\n",
    "\n",
    "    print(f\"Topic: {summary.get('topic')}\")\n",
    "\n",
    "    embeddings = calculate_embeddings(comments, model, show_progress_bar=True)\n",
    "    comments.addColumns(pl.Series(embeddings).alias(f\"embedding-{EMBED_MODEL_ID}\"))\n",
    "    comments.save_to_parquet()\n",
    "    print(f\"{dataset}: Saved {comments.df.height} comments with embeddings to Parquet DataFrame.\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "argmap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
